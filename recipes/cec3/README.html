<!DOCTYPE html>

<html lang="en" data-content_root="../../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>The 3rd Clarity Enhancement Challenge (CEC3) &#8212; Project name not set  documentation</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=5ecbeea2" />
    <link rel="stylesheet" type="text/css" href="../../_static/alabaster.css?v=12dfc556" />
    <script src="../../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="the-3rd-clarity-enhancement-challenge-cec3">
<h1>The 3rd Clarity Enhancement Challenge (CEC3)<a class="headerlink" href="#the-3rd-clarity-enhancement-challenge-cec3" title="Link to this heading">¶</a></h1>
<p>Clarity challenge code for the 3rd Clarity Enhancement Challenge.</p>
<p>For more information please visit the <a class="reference external" href="https://claritychallenge.org/docs/cec3/cec3_intro">challenge website</a>.</p>
<p>Clarity tutorials are <a class="reference external" href="https://claritychallenge.github.io/clarity_CC_doc/tutorials">now available</a>. The tutorials introduce the Clarity installation, how to interact with Clarity metadata, and also provide examples of baseline systems and evaluation tools.</p>
<section id="data-structure">
<h2>Data structure<a class="headerlink" href="#data-structure" title="Link to this heading">¶</a></h2>
<p>The 3rd Clarity Enhancement Challenge consists of three separate tasks each with its own training and evaluation data. Details for how to obtain the data can be found on the <a class="reference external" href="https://claritychallenge.org/docs/cec3/cec3_data">challenge website</a>.</p>
<p>The data is distributed as one or more separate packages in <code class="docutils literal notranslate"><span class="pre">tar.gz</span></code> format.</p>
<p>Unpack all packages under the same root directory using</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>tar<span class="w"> </span>-xvzf<span class="w"> </span>&lt;PACKAGE_NAME&gt;
</pre></div>
</div>
<p>The initially released data is in the package <code class="docutils literal notranslate"><span class="pre">clarity_CEC3_data.v1_0.tar.gz</span></code> and has the following structure:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>clarity_CEC3_data
|── manifest
|── task1
|   |── clarity_data
|   |   |── dev
|   |   |   |── scenes
|   |   |   └── speaker_adapt
|   |   |── metadata
|   |   └── train
|   └── hrir
|       └── HRIRs_MAT
|── task2
|   └── clarity_data
|       |── dev
|       |   |── interferers
|       |   |── scenes
|       |   |── speaker_adapt
|       |   └── targets
|       |── metadata
|       └── train
|           |── interferers
|           |── scenes
|           └── targets
└── task3
</pre></div>
</div>
</section>
<section id="baseline">
<h2>Baseline<a class="headerlink" href="#baseline" title="Link to this heading">¶</a></h2>
<p>In the `baseline/’ folder, we provide code for running the baseline enhancement system and performing the objective evaluation. The same system can be used for all three tasks by setting the configuration appropriately.</p>
<p>The scripts are controlled by three variables.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">task</span></code> - The task to evaluate. This can be <code class="docutils literal notranslate"><span class="pre">task1</span></code>, <code class="docutils literal notranslate"><span class="pre">task2</span></code> or <code class="docutils literal notranslate"><span class="pre">task3</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">path.root</span></code> - The root directory where you clarity data is stored.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">path.exp</span></code> - A directory that will be used to store intermediate files and the final evaluation results.</p></li>
</ul>
<p>These can be set in the <code class="docutils literal notranslate"><span class="pre">config.yaml</span></code> file or provided on the command line. In the following they are being set on the command line.</p>
<section id="enhancement">
<h3>Enhancement<a class="headerlink" href="#enhancement" title="Link to this heading">¶</a></h3>
<p>The baseline enhancement simply takes the 6-channel hearing aid inputs and reduces this to a stereo hearing aid output by passing through the ‘front’ microphone signal of the left and right ear.</p>
<p>The stereo pair is then passed through a provided hearing aid amplification stage using a NAL-R [<a class="reference internal" href="#references"><span class="xref myst">1</span></a>] fitting amplification and a simple automatic gain compressor. The amplification is determined by the audiograms defined by the scene-listener pairs in <code class="docutils literal notranslate"><span class="pre">clarity_data/metadata/scenes_listeners.dev.json</span></code> for the development set. After amplification, the evaluate function calculates the better-ear HASPI  [<a class="reference internal" href="#references"><span class="xref myst">2</span></a>].</p>
<p>To run the baseline enhancement system use, first set the <code class="docutils literal notranslate"><span class="pre">task</span></code>, <code class="docutils literal notranslate"><span class="pre">path.root</span></code> and <code class="docutils literal notranslate"><span class="pre">path.exp</span></code> variables in the <code class="docutils literal notranslate"><span class="pre">config.yaml</span></code> file and then run,</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>enhance.py
</pre></div>
</div>
<p>Alternatively, you can provide the task and paths on the command line, e.g.,</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>enhance.py<span class="w"> </span><span class="nv">task</span><span class="o">=</span>task1<span class="w"> </span>path.root<span class="o">=</span>/Users/jon/clarity_CEC3_data<span class="w"> </span>path.exp<span class="o">=</span>/Users/jon/exp
</pre></div>
</div>
<p>Where <code class="docutils literal notranslate"><span class="pre">/Users/jon</span></code> is replaced with the path to the root of the clarity data and the experiment folder.</p>
<p>The folders <code class="docutils literal notranslate"><span class="pre">enhanced_signals</span></code>  and <code class="docutils literal notranslate"><span class="pre">amplified_signals</span></code> will appear in the <code class="docutils literal notranslate"><span class="pre">exp</span></code> folder. Note, the experiment folder will be created if it does not already exist.</p>
</section>
<section id="evaluation">
<h3>Evaluation<a class="headerlink" href="#evaluation" title="Link to this heading">¶</a></h3>
<p>The evaluate script computes the HASPI scores for the signals stored in the <code class="docutils literal notranslate"><span class="pre">amplified_signals</span></code> folder. The script will read the scene-listener pairs from the development set and calculate the HASPI score for each pair. The final score is the mean HASPI score across all pairs. It can be run as,</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>evaluate.py<span class="w"> </span><span class="nv">task</span><span class="o">=</span>task1<span class="w"> </span>path.root<span class="o">=</span>/Users/jon/clarity_CEC3_data<span class="w"> </span>path.exp<span class="o">=</span>/Users/jon/exp
</pre></div>
</div>
<p>The full evaluation set is 7500 scene-listener pairs and will take a long time to run, i.e., around 8 hours on a MacBook Pro. A standard small set which uses 1/15 of the data has been defined. This takes around 30 minutes to evaluate and can be run with,</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>evaluate.py<span class="w"> </span><span class="nv">task</span><span class="o">=</span>task1<span class="w"> </span>path.root<span class="o">=</span>/Users/jon/clarity_CEC3_data<span class="w"> </span>path.exp<span class="o">=</span>/Users/jon/exp<span class="w"> </span>evaluate.small_test<span class="o">=</span>True
</pre></div>
</div>
<p>Alternatively, see the section below, ‘Running with multiple threads’, for how to run with multiple threads or on an HPC system.</p>
<p>The evaluation script will generate a CSV file containing the HASPI scores for each sample. This can be found in <code class="docutils literal notranslate"><span class="pre">&lt;path.exp&gt;/scores</span></code></p>
</section>
<section id="reporting-results">
<h3>Reporting results<a class="headerlink" href="#reporting-results" title="Link to this heading">¶</a></h3>
<p>Once the evaluation script has finished running, the final result can be reported with</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>report_score.py<span class="w"> </span><span class="nv">task</span><span class="o">=</span>task1<span class="w"> </span>path.root<span class="o">=</span>/Users/jon/clarity_CEC3_data<span class="w"> </span>path.exp<span class="o">=</span>/Users/jon/exp
</pre></div>
</div>
<p>Or if you have run the small evaluation</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>report_score.py<span class="w"> </span><span class="nv">task</span><span class="o">=</span>task1<span class="w"> </span>path.root<span class="o">=</span>/Users/jon/clarity_CEC3_data<span class="w"> </span>path.exp<span class="o">=</span>/Users/jon/exp<span class="w"> </span>evaluate.small_test<span class="o">=</span>True
</pre></div>
</div>
<p>The scores for Task 1 and Task 2 should be as follows.</p>
<p>Task 1</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Evaluation set size: 7500
Mean HASPI score: 0.22178678134846783

                 SNR     haspi
SNR
(-12, -9] -10.498088  0.052545
(-9, -6]   -7.541468  0.080589
(-6, -3]   -4.477046  0.143096
(-3, 0]    -1.432494  0.239527
(0, 3]      1.470118  0.352110
(3, 6]      4.492380  0.477001
</pre></div>
</div>
<p>Task 2</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Evaluation set size: 7500
Mean HASPI score: 0.18643217215546573

                 SNR     haspi
SNR
(-12, -9] -10.545927  0.034330
(-9, -6]   -7.552687  0.055647
(-6, -3]   -4.538335  0.096237
(-3, 0]    -1.455963  0.178413
(0, 3]      1.434074  0.296364
(3, 6]      4.507484  0.432177
</pre></div>
</div>
</section>
</section>
<section id="tips">
<h2>Tips<a class="headerlink" href="#tips" title="Link to this heading">¶</a></h2>
<section id="configuring-with-hydra">
<h3>Configuring with Hydra<a class="headerlink" href="#configuring-with-hydra" title="Link to this heading">¶</a></h3>
<p>The code is using <a class="reference external" href="https://hydra.cc">Hydra</a> for configuration management. This allows for easy configuration of the system. The configuration file is <code class="docutils literal notranslate"><span class="pre">config.yaml</span></code> in the <code class="docutils literal notranslate"><span class="pre">baseline</span></code> folder. The task, root and exp variables can be set in this file to avoid having to set them on every command line. Simply replace the <code class="docutils literal notranslate"><span class="pre">???</span></code> entries with the appropriate values.</p>
<p>You can make alternative configurations and store them in separate <code class="docutils literal notranslate"><span class="pre">yaml</span></code> files. These can then be used to override the default configuration, e.g.,</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>enhance.py<span class="w"> </span>python<span class="w"> </span>report_score.py<span class="w"> </span>--config-name<span class="w"> </span>my_task1_config.yaml
</pre></div>
</div>
<p>You can get help on any of the commands with</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>enhance.py<span class="w"> </span>--help
</pre></div>
</div>
<p>And specific help on Hydra usage with</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>enhance.py<span class="w"> </span>--hydra-help
</pre></div>
</div>
</section>
<section id="running-with-multiple-threads">
<h3>Running with multiple threads<a class="headerlink" href="#running-with-multiple-threads" title="Link to this heading">¶</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">evaluate.py</span></code> script can be sped up by running with multiple processes, i.e. each process will evaluate a separate block of scenes and generate its own csv file. The <code class="docutils literal notranslate"><span class="pre">report_score.py</span></code> script will then combine these csv files to produce a single result.</p>
<p>To do this we can use the Hydra <code class="docutils literal notranslate"><span class="pre">--multirun</span></code> flag and set multiple values for <code class="docutils literal notranslate"><span class="pre">evaluate.first_scene</span></code>. For example, to run with 4 threads we can split the 7500 scenes into 4 blocks of 1875 scenes each and run with,</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>evaluate.py<span class="w"> </span>evaluate.first_scene<span class="o">=</span><span class="s2">&quot;0,1875,3750,5625&quot;</span><span class="w"> </span>evaluate.n_scenes<span class="o">=</span><span class="m">1875</span><span class="w"> </span>--multirun
</pre></div>
</div>
<p>Hydra has a Python like system for specifying ranges, so the above command is equivalent to</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>evaluate.py<span class="w">  </span>evaluate.first_scene<span class="o">=</span><span class="s2">&quot;range(0,7500,1875) evaluate.n_scenes=1875 --multirun</span>
</pre></div>
</div>
<p>If we wanted to split into jobs with just 100 scenes per job we could use</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>evaluate.py<span class="w"> </span>evaluate.first_scene<span class="o">=</span><span class="s2">&quot;range(0,7500,100)&quot;</span><span class="w"> </span>evaluate.n_scenes<span class="o">=</span><span class="m">500</span><span class="w"> </span>--multirun
</pre></div>
</div>
<p>Hydra will launch these job using configuration that can be found in <code class="docutils literal notranslate"><span class="pre">hydra/launcher/cec3_submitit_local.yaml</span></code>.</p>
<p>The same approach can be used to run jobs on a SLURM cluster using configuration in <code class="docutils literal notranslate"><span class="pre">hydra/launcher/cec3_submitit_slurm.yaml</span></code>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>evaluate.py<span class="w"> </span>hydra/launcher<span class="o">=</span>cec3_submitit_slurm<span class="w"> </span>evaluate.first_scene<span class="o">=</span><span class="s2">&quot;range(0,7500,100)&quot;</span><span class="w"> </span>evaluate.n_scenes<span class="o">=</span><span class="m">100</span><span class="w"> </span>--multirun
</pre></div>
</div>
<p>!!!Note In the examples above it is assumed that the <code class="docutils literal notranslate"><span class="pre">task</span></code>, <code class="docutils literal notranslate"><span class="pre">path.root</span></code> and <code class="docutils literal notranslate"><span class="pre">path.exp</span></code> variables are set in the <code class="docutils literal notranslate"><span class="pre">config.yaml</span></code> file.</p>
<p>!!!Note Hydra has plugin support for other job launchers. See the <a class="reference external" href="https://hydra.cc/docs/intro/">Hydra documentation for more information</a>.</p>
</section>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Link to this heading">¶</a></h2>
<ul class="simple">
<li><p>[1] Byrne, Denis, and Harvey Dillon. “The National Acoustic Laboratories’(NAL) new procedure for selecting the gain and frequency response of a hearing aid.” Ear and hearing 7.4 (1986): 257-265.</p></li>
<li><p>[2] Kates J M, Arehart K H. The hearing-aid speech perception index (HASPI) J. Speech Communication, 2014, 65: 75-93.</p></li>
</ul>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../index.html">Project name not set</a></h1>








<h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage.html">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../recipes_doc.html">Recipes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../CONTRIBUTING.html">Contributing to pyClarity</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../CODE_OF_CONDUCT.html">Contributor Covenant Code of Conduct</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../clarity.html">clarity package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../recipes.html">recipes package</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<search id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 7.4.7</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 0.7.16</a>
      
      |
      <a href="../../_sources/recipes/cec3/README.md.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>