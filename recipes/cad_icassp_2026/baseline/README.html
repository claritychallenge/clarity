<!DOCTYPE html>

<html lang="en" data-content_root="../../../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>The ICASSP 2026 Cadenza Challenge: Predicting Lyric Intelligibility (CLIP1) baseline code &#8212; Project name not set  documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=5ecbeea2" />
    <link rel="stylesheet" type="text/css" href="../../../_static/alabaster.css?v=12dfc556" />
    <script src="../../../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
   
  <link rel="stylesheet" href="../../../_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="the-icassp-2026-cadenza-challenge-predicting-lyric-intelligibility-clip1-baseline-code">
<h1>The ICASSP 2026 Cadenza Challenge: Predicting Lyric Intelligibility (CLIP1) baseline code<a class="headerlink" href="#the-icassp-2026-cadenza-challenge-predicting-lyric-intelligibility-clip1-baseline-code" title="Link to this heading">¶</a></h1>
<p>Code to support the ICASSP 2026 Cadenza Challenge (CLIP1)</p>
<p>For more information about the CLIP1 please <a class="reference external" href="https://cadenzachallenge.org/">visit</a></p>
<section id="data-structure">
<h2>1. Data Structure<a class="headerlink" href="#data-structure" title="Link to this heading">¶</a></h2>
<section id="obtaining-the-clip1-data">
<h3>1.1 Obtaining the CLIP1 data<a class="headerlink" href="#obtaining-the-clip1-data" title="Link to this heading">¶</a></h3>
<p>To download the CLIP1 data, please <a class="reference external" href="https://cadenzachallenge.org/docs/clip1/take_part/registration">register</a>.</p>
<p>The data will download into two package files called <code class="docutils literal notranslate"><span class="pre">cadenza_clip1_data.train.v1.0.tar.gz</span></code> and <code class="docutils literal notranslate"><span class="pre">cadenza_clip1_data.valid.v1.0.tar.gz</span></code></p>
<p>Unpack these packages under the same root using</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>tar<span class="w"> </span>-xvzf<span class="w"> </span>cadenza_clip1_data.train.v1.0.tar.gz<span class="w">  </span><span class="c1"># For training data</span>
tar<span class="w"> </span>-xvzf<span class="w"> </span>cadenza_clip1_data.valid.v1.0.tar.gz<span class="w"> </span><span class="c1"># For validation data</span>
</pre></div>
</div>
<p>Once unpacked the directory structure will be as follows</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>cadenza_data/
├──<span class="w"> </span>metadata/
├──<span class="w"> </span>train/
│<span class="w">   </span>├──<span class="w"> </span>signals/<span class="w">      </span><span class="c1"># Audio (1) to predict intelligibility</span>
│<span class="w">   </span>└──<span class="w"> </span>unprocessed/<span class="w">  </span><span class="c1"># Audio (2) without hearing loss</span>
├──<span class="w"> </span>valid/
│<span class="w">   </span>├──<span class="w"> </span>signals/
│<span class="w">   </span>└──<span class="w"> </span>unprocessed/
└──<span class="w"> </span>Manifest/
</pre></div>
</div>
</section>
<section id="demo-data">
<h3>1.2 Demo data<a class="headerlink" href="#demo-data" title="Link to this heading">¶</a></h3>
<p>Running the baseline code over the full dataset can be quite time consuming.
To allow you to easily try out the code with a small amount of data, we have provided a small subset of demo data containing 10 signals.</p>
<p>To use the demo data download the file <code class="docutils literal notranslate"><span class="pre">cadenza_clip1_data.demo.v1.0.tar.gz</span></code> which can be found at the same download sites as the full dataset.</p>
<p>Unpack this package under this directory, i.e., under <code class="docutils literal notranslate"><span class="pre">recipes/cad_icassp_2026/baseline</span></code> using</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>tar<span class="w"> </span>-xvzf<span class="w"> </span>cadenza_clip1_data.demo.v1.0.tar.gz
</pre></div>
</div>
<p>Note, you need to set the <code class="docutils literal notranslate"><span class="pre">root.path</span></code> variable to the parent directory of <code class="docutils literal notranslate"><span class="pre">cadenza_data</span></code> in <code class="docutils literal notranslate"><span class="pre">common.yaml</span></code> config file.</p>
</section>
<section id="precomputed-scores">
<h3>1.3 Precomputed Scores<a class="headerlink" href="#precomputed-scores" title="Link to this heading">¶</a></h3>
<p>For convenience, precomputed STOI and Whisper correctness scores are provided in the <code class="docutils literal notranslate"><span class="pre">precomputed</span></code> directory.
These scores are stored in JSONL files and can be used directly without running the <code class="docutils literal notranslate"><span class="pre">compute_stoi.py</span></code> or <code class="docutils literal notranslate"><span class="pre">compute_whisper</span></code> scripts.
The files are named as follows:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">cadenza_data.train.stoi.jsonl</span></code>: Contains precomputed STOI scores for the training set.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cadenza_data.valid.stoi.jsonl</span></code>: Contains precomputed STOI scores for the validation set.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cadenza_data.train.whisper.mixture.jsonl</span></code>: Contains precomputed Whisper correctness scores from the mixture for the training set.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cadenza_data.valid.whisper.mixture.jsonl</span></code>: Contains precomputed Whisper correctness scores from the mixture for the validation set.</p></li>
</ul>
<p>To use these precomputed scores, copy the relevant file to the <code class="docutils literal notranslate"><span class="pre">exp/</span></code> directory and rename it to match the expected output of the <code class="docutils literal notranslate"><span class="pre">compute_stoi.py</span></code> or <code class="docutils literal notranslate"><span class="pre">compute_whisper.py</span></code> scripts.
For example, to copy the precomputed STOI scores for the training set, run:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>cp<span class="w"> </span>precomputed/cadenza_data.train.stoi.jsonl<span class="w"> </span>exp/cadenza_data.train.stoi.jsonl
</pre></div>
</div>
<p>This allows you to skip the computation step and proceed directly to making intelligibility predictions.</p>
</section>
</section>
<section id="baseline">
<h2>2. Baseline<a class="headerlink" href="#baseline" title="Link to this heading">¶</a></h2>
<p>The baseline prediction model is a simple logistic regression model that maps STOI or Whisper correctness scores onto the sentence correctness values.</p>
<p>There are two baselines:</p>
<ol class="arabic simple">
<li><p>STOI-based baseline</p></li>
<li><p>Whisper-based baseline using the mixture as input</p></li>
</ol>
<section id="stoi-based-baseline">
<h3>2.1 STOI-Based baseline<a class="headerlink" href="#stoi-based-baseline" title="Link to this heading">¶</a></h3>
<p>The STOI-based baseline uses the Short-Time Objective Intelligibility (STOI) metric to predict the intelligibility of the audio signals.
For reference signal, it estimates the vocals from the unprocessed signal.</p>
</section>
<section id="whisper-based-baseline">
<h3>2.2 Whisper-Based baseline<a class="headerlink" href="#whisper-based-baseline" title="Link to this heading">¶</a></h3>
<p>The Whisper-based baseline uses OpenAI’s Whisper model to transcribe the audio signals and compute a correctness score.
It uses the processed signal as input to Whisper and computes the <code class="docutils literal notranslate"><span class="pre">hits/total_words</span></code> as score.
The transcription and ground truth are normalised and contractions expanded before computing the correctness.</p>
</section>
</section>
<section id="running-the-baseline">
<h2>3. Running the Baseline<a class="headerlink" href="#running-the-baseline" title="Link to this heading">¶</a></h2>
<section id="computing-scores">
<h3>3.1 Computing scores<a class="headerlink" href="#computing-scores" title="Link to this heading">¶</a></h3>
<p>To compute the scores for the training data set, run the following commands:</p>
<p>For stoi:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>compute_stoi.py<span class="w"> </span>data.cadenza_data_root<span class="o">=</span>/path/to/cadenza_data/parent<span class="w"> </span><span class="nv">split</span><span class="o">=</span>train<span class="w"> </span>baseline.system<span class="o">=</span>stoi
</pre></div>
</div>
<p>For Whisper:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>compute_whisper.py<span class="w"> </span>data.cadenza_data_root<span class="o">=</span>/path/to/cadenza_data/parent<span class="w"> </span><span class="nv">split</span><span class="o">=</span>train<span class="w"> </span>baseline.system<span class="o">=</span>whisper
</pre></div>
</div>
<p>This will generate an output file containing the corresponding scores.
The file will be saved in the <code class="docutils literal notranslate"><span class="pre">exp/</span></code> directory and named <code class="docutils literal notranslate"><span class="pre">&lt;DATASET&gt;.train.&lt;BASELINE</span> <span class="pre">SYSTEM&gt;.jsonl</span></code>, where <code class="docutils literal notranslate"><span class="pre">&lt;DATASET&gt;</span></code> is the dataset name specified in the command (e.g., <code class="docutils literal notranslate"><span class="pre">cadenza_data</span></code>).</p>
<p>To run the same commands for the validation set, simply change the <code class="docutils literal notranslate"><span class="pre">split</span></code> argument to <code class="docutils literal notranslate"><span class="pre">valid</span></code>.</p>
</section>
<section id="making-intelligibility-predictions">
<h3>3.2 Making intelligibility predictions<a class="headerlink" href="#making-intelligibility-predictions" title="Link to this heading">¶</a></h3>
<p>The baseline intelligibility predictions are made by using a logistic fitting to map the corresponding scores onto the sentence correctness values.
This is done using <code class="docutils literal notranslate"><span class="pre">predict.py</span></code>, which will produce a CSV file named <code class="docutils literal notranslate"><span class="pre">exp/&lt;DATASET&gt;.train.&lt;BASELINE</span> <span class="pre">SYSTEM&gt;.predict.csv</span></code> containing the predictions in the format required for submission to the challenge.</p>
<p>For example, to make predictions for the validation set using the STOI-based baseline, run:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>predict.py<span class="w"> </span>data.cadenza_data_root<span class="o">=</span>/path/to/cadenza_data/parent<span class="w"> </span><span class="nv">split</span><span class="o">=</span>valid<span class="w"> </span>baseline.system<span class="o">=</span>stoi
</pre></div>
</div>
</section>
<section id="evaluating-the-predictions">
<h3>3.3 Evaluating the predictions<a class="headerlink" href="#evaluating-the-predictions" title="Link to this heading">¶</a></h3>
<p>Finally, the <code class="docutils literal notranslate"><span class="pre">evaluate.py</span></code> script will compare the provided predictions with the ground truth and compute the error metrics.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>evaluate.py<span class="w"> </span>data.cadenza_data_root<span class="o">=</span>/path/to/cadenza_data/parent<span class="w"> </span><span class="nv">split</span><span class="o">=</span>valid<span class="w"> </span>baseline.system<span class="o">=</span>stoi
</pre></div>
</div>
<p>Results will be displayed on the terminal and saved to the file <code class="docutils literal notranslate"><span class="pre">exp/&lt;DATASET&gt;.&lt;BASELINE</span> <span class="pre">SYSTEM&gt;evaluate.jsonl</span></code>.</p>
<p>These predictions are intended for submission to the leaderboard for evaluation. See the challenge website for details on how to submit your predictions.</p>
</section>
<section id="id1">
<h3>3.4 Evaluating the predictions<a class="headerlink" href="#id1" title="Link to this heading">¶</a></h3>
<p>Unlike for the training data set, the validation set ground truth is not provided, but once predictions are made they can be submitted to the leaderboard for evaluation.
See the challenge website for details of how to submit your predictions.</p>
</section>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../index.html">Project name not set</a></h1>








<h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../usage.html">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../recipes_doc.html">Recipes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../CONTRIBUTING.html">Contributing to pyClarity</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../CODE_OF_CONDUCT.html">Contributor Covenant Code of Conduct</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../clarity.html">clarity package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../recipes.html">recipes package</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<search id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 7.4.7</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 0.7.16</a>
      
      |
      <a href="../../../_sources/recipes/cad_icassp_2026/baseline/README.md.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>