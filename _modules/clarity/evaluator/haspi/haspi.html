<!DOCTYPE html>

<html lang="en" data-content_root="../../../../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>clarity.evaluator.haspi.haspi &#8212; Project name not set  documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css?v=5ecbeea2" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/alabaster.css?v=12dfc556" />
    <script src="../../../../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script type="module" src="https://cdn.jsdelivr.net/npm/mermaid@11.12.1/dist/mermaid.esm.min.mjs"></script>
    <script type="module" src="https://cdn.jsdelivr.net/npm/@mermaid-js/layout-elk@0.2.0/dist/mermaid-layout-elk.esm.min.mjs"></script>
    <script type="module">import mermaid from "https://cdn.jsdelivr.net/npm/mermaid@11.12.1/dist/mermaid.esm.min.mjs";import elkLayouts from "https://cdn.jsdelivr.net/npm/@mermaid-js/layout-elk@0.2.0/dist/mermaid-layout-elk.esm.min.mjs";mermaid.registerLayoutLoaders(elkLayouts);mermaid.initialize({startOnLoad:false});</script>
    <script src="https://cdn.jsdelivr.net/npm/d3@7.9.0/dist/d3.min.js"></script>
    <script type="module">import mermaid from "https://cdn.jsdelivr.net/npm/mermaid@11.12.1/dist/mermaid.esm.min.mjs";

const defaultStyle = document.createElement('style');
defaultStyle.textContent = `pre.mermaid {
    /* Same as .mermaid-container > pre */
    display: block;
    width: 100%;
}

pre.mermaid > svg {
    /* Same as .mermaid-container > pre > svg */
    height: 500px;
    width: 100%;
    max-width: 100% !important;
}
`;
document.head.appendChild(defaultStyle);

const fullscreenStyle = document.createElement('style');
fullscreenStyle.textContent = `.mermaid-container {
    display: flex;
    flex-direction: row;
    width: 100%;
}

.mermaid-container > pre {
    display: block;
    width: 100%;
}

.mermaid-container > pre > svg {
    height: 500px;
    width: 100%;
    max-width: 100% !important;
}

.mermaid-fullscreen-btn {
    width: 28px;
    height: 28px;
    background: rgba(255, 255, 255, 0.95);
    border: 1px solid rgba(0, 0, 0, 0.3);
    border-radius: 4px;
    cursor: pointer;
    display: flex;
    align-items: center;
    justify-content: center;
    transition: all 0.2s;
    box-shadow: 0 2px 6px rgba(0, 0, 0, 0.2);
    font-size: 14px;
    line-height: 1;
    padding: 0;
    color: #333;
}

.mermaid-fullscreen-btn:hover {
    opacity: 100% !important;
    background: rgba(255, 255, 255, 1);
    box-shadow: 0 3px 10px rgba(0, 0, 0, 0.3);
    transform: scale(1.1);
}

.mermaid-fullscreen-btn.dark-theme {
    background: rgba(50, 50, 50, 0.95);
    border: 1px solid rgba(255, 255, 255, 0.3);
    color: #e0e0e0;
}

.mermaid-fullscreen-btn.dark-theme:hover {
    background: rgba(60, 60, 60, 1);
    box-shadow: 0 3px 10px rgba(255, 255, 255, 0.2);
}

.mermaid-fullscreen-modal {
    display: none;
    position: fixed !important;
    top: 0 !important;
    left: 0 !important;
    width: 95vw;
    height: 100vh;
    background: rgba(255, 255, 255, 0.98);
    z-index: 9999;
    padding: 20px;
    overflow: auto;
}

.mermaid-fullscreen-modal.dark-theme {
    background: rgba(0, 0, 0, 0.98);
}

.mermaid-fullscreen-modal.active {
    display: flex;
    align-items: center;
    justify-content: center;
}

.mermaid-container-fullscreen {
    position: relative;
    width: 95vw;
    height: 90vh;
    max-width: 95vw;
    max-height: 90vh;
    background: white;
    border-radius: 8px;
    padding: 20px;
    box-shadow: 0 10px 40px rgba(0, 0, 0, 0.3);
    overflow: auto;
    display: flex;
    align-items: center;
    justify-content: center;
}

.mermaid-container-fullscreen.dark-theme {
    background: #1a1a1a;
    box-shadow: 0 10px 40px rgba(0, 0, 0, 0.8);
}

.mermaid-container-fullscreen pre.mermaid {
    width: 100%;
    height: 100%;
    display: flex;
    align-items: center;
    justify-content: center;
}

.mermaid-container-fullscreen .mermaid svg {
    height: 100% !important;
    width: 100% !important;
    cursor: grab;
}

.mermaid-fullscreen-close {
    position: fixed !important;
    top: 20px !important;
    right: 20px !important;
    width: 40px;
    height: 40px;
    background: rgba(255, 255, 255, 0.95);
    border: 1px solid rgba(0, 0, 0, 0.2);
    border-radius: 50%;
    cursor: pointer;
    z-index: 10000;
    display: flex;
    align-items: center;
    justify-content: center;
    box-shadow: 0 4px 12px rgba(0, 0, 0, 0.3);
    transition: all 0.2s;
    font-size: 24px;
    line-height: 1;
    color: #333;
}

.mermaid-fullscreen-close:hover {
    background: white;
    box-shadow: 0 6px 16px rgba(0, 0, 0, 0.4);
    transform: scale(1.1);
}

.mermaid-fullscreen-close.dark-theme {
    background: rgba(50, 50, 50, 0.95);
    border: 1px solid rgba(255, 255, 255, 0.2);
    color: #e0e0e0;
}

.mermaid-fullscreen-close.dark-theme:hover {
    background: rgba(60, 60, 60, 1);
    box-shadow: 0 6px 16px rgba(255, 255, 255, 0.2);
}

.mermaid-fullscreen-modal .mermaid-fullscreen-btn {
    display: none !important;
}`;
document.head.appendChild(fullscreenStyle);

// Detect if page has dark background
const isDarkTheme = () => {
    const bgColor = window.getComputedStyle(document.body).backgroundColor;
    const match = bgColor.match(/rgb\((\d+),\s*(\d+),\s*(\d+)/);
    if (match) {
        const r = parseInt(match[1]);
        const g = parseInt(match[2]);
        const b = parseInt(match[3]);
        const brightness = (r * 299 + g * 587 + b * 114) / 1000;
        return brightness < 128;
    }
    return false;
};

const load = async () => {
    await mermaid.run();

    const all_mermaids = document.querySelectorAll(".mermaid");
    const mermaids_processed = document.querySelectorAll(".mermaid[data-processed='true']");

    if ("False" === "True") {
        const mermaids_to_add_zoom = -1 === -1 ? all_mermaids.length : -1;
        if(mermaids_to_add_zoom > 0) {
            var svgs = d3.selectAll("");
            if(all_mermaids.length !== mermaids_processed.length) {
                setTimeout(load, 200);
                return;
            } else if(svgs.size() !== mermaids_to_add_zoom) {
                setTimeout(load, 200);
                return;
            } else {
                svgs.each(function() {
                    var svg = d3.select(this);
                    svg.html("<g class='wrapper'>" + svg.html() + "</g>");
                    var inner = svg.select("g");
                    var zoom = d3.zoom().on("zoom", function(event) {
                        inner.attr("transform", event.transform);
                    });
                    svg.call(zoom);
                });
            }
        }
    } else if(all_mermaids.length !== mermaids_processed.length) {
        // Wait for mermaid to process all diagrams
        setTimeout(load, 200);
        return;
    }

    const darkTheme = isDarkTheme();

    // Stop here if not adding fullscreen capability
    if ("True" !== "True") return;

    const modal = document.createElement('div');
    modal.className = 'mermaid-fullscreen-modal' + (darkTheme ? ' dark-theme' : '');
    modal.setAttribute('role', 'dialog');
    modal.setAttribute('aria-modal', 'true');
    modal.setAttribute('aria-label', 'Fullscreen diagram viewer');
    modal.innerHTML = `
        <button class="mermaid-fullscreen-close${darkTheme ? ' dark-theme' : ''}" aria-label="Close fullscreen">✕</button>
        <div class="mermaid-container-fullscreen${darkTheme ? ' dark-theme' : ''}"></div>
    `;
    document.body.appendChild(modal);

    const modalContent = modal.querySelector('.mermaid-container-fullscreen');
    const closeBtn = modal.querySelector('.mermaid-fullscreen-close');

    let previousScrollOffset = [window.scrollX, window.scrollY];

    const closeModal = () => {
        modal.classList.remove('active');
        modalContent.innerHTML = '';
        document.body.style.overflow = ''
        window.scrollTo({left: previousScrollOffset[0], top: previousScrollOffset[1], behavior: 'instant'});
    };

    closeBtn.addEventListener('click', closeModal);
    modal.addEventListener('click', (e) => {
        if (e.target === modal) closeModal();
    });
    document.addEventListener('keydown', (e) => {
        if (e.key === 'Escape' && modal.classList.contains('active')) {
            closeModal();
        }
    });

    const allButtons = [];

    document.querySelectorAll('.mermaid').forEach((mermaidDiv) => {
        if (mermaidDiv.parentNode.classList.contains('mermaid-container') ||
            mermaidDiv.closest('.mermaid-fullscreen-modal')) {
            return;
        }

        const container = document.createElement('div');
        container.className = 'mermaid-container';
        mermaidDiv.parentNode.insertBefore(container, mermaidDiv);
        container.appendChild(mermaidDiv);

        const fullscreenBtn = document.createElement('button');
        fullscreenBtn.className = 'mermaid-fullscreen-btn' + (darkTheme ? ' dark-theme' : '');
        fullscreenBtn.setAttribute('aria-label', 'View diagram in fullscreen');
        fullscreenBtn.textContent = '⛶';
        fullscreenBtn.style.opacity = '50%';

        // Calculate dynamic position based on diagram's margin and padding
        const diagramStyle = window.getComputedStyle(mermaidDiv);
        const marginTop = parseFloat(diagramStyle.marginTop) || 0;
        const marginRight = parseFloat(diagramStyle.marginRight) || 0;
        const paddingTop = parseFloat(diagramStyle.paddingTop) || 0;
        const paddingRight = parseFloat(diagramStyle.paddingRight) || 0;
        fullscreenBtn.style.top = `${marginTop + paddingTop + 4}px`;
        fullscreenBtn.style.right = `${marginRight + paddingRight + 4}px`;

        fullscreenBtn.addEventListener('click', () => {
            previousScrollOffset = [window.scroll, window.scrollY];
            const clone = mermaidDiv.cloneNode(true);
            modalContent.innerHTML = '';
            modalContent.appendChild(clone);

            const svg = clone.querySelector('svg');
            if (svg) {
                svg.removeAttribute('width');
                svg.removeAttribute('height');
                svg.style.width = '100%';
                svg.style.height = 'auto';
                svg.style.maxWidth = '100%';
                svg.style.sdisplay = 'block';

                if ("False" === "True") {
                    setTimeout(() => {
                        const g = svg.querySelector('g');
                        if (g) {
                            var svgD3 = d3.select(svg);
                            svgD3.html("<g class='wrapper'>" + svgD3.html() + "</g>");
                            var inner = svgD3.select("g");
                            var zoom = d3.zoom().on("zoom", function(event) {
                                inner.attr("transform", event.transform);
                            });
                            svgD3.call(zoom);
                        }
                    }, 100);
                }
            }

            modal.classList.add('active');
            document.body.style.overflow = 'hidden';
        });

        container.appendChild(fullscreenBtn);
        allButtons.push(fullscreenBtn);
    });

    // Update theme classes when theme changes
    const updateTheme = () => {
        const dark = isDarkTheme();
        allButtons.forEach(btn => {
            if (dark) {
                btn.classList.add('dark-theme');
            } else {
                btn.classList.remove('dark-theme');
            }
        });
        if (dark) {
            modal.classList.add('dark-theme');
            modalContent.classList.add('dark-theme');
            closeBtn.classList.add('dark-theme');
        } else {
            modal.classList.remove('dark-theme');
            modalContent.classList.remove('dark-theme');
            closeBtn.classList.remove('dark-theme');
        }
    };

    // Watch for theme changes
    const observer = new MutationObserver(updateTheme);
    observer.observe(document.documentElement, {
        attributes: true,
        attributeFilter: ['class', 'style', 'data-theme']
    });
    observer.observe(document.body, {
        attributes: true,
        attributeFilter: ['class', 'style']
    });
};

window.addEventListener("load", load);
</script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
   
  <link rel="stylesheet" href="../../../../_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <h1>Source code for clarity.evaluator.haspi.haspi</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;HASPI intelligibility Index&quot;&quot;&quot;</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">__future__</span><span class="w"> </span><span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">logging</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">TYPE_CHECKING</span><span class="p">,</span> <span class="n">Final</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">clarity.evaluator.haspi.eb</span><span class="w"> </span><span class="kn">import</span> <span class="n">ear_model</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">clarity.evaluator.haspi.ebm</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">cepstral_correlation_coef</span><span class="p">,</span>
    <span class="n">env_filter</span><span class="p">,</span>
    <span class="n">fir_modulation_filter</span><span class="p">,</span>
    <span class="n">modulation_cross_correlation</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">clarity.evaluator.haspi.ip</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_neural_net</span><span class="p">,</span> <span class="n">nn_feed_forward_ensemble</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">clarity.utils.audiogram</span><span class="w"> </span><span class="kn">import</span> <span class="n">Audiogram</span><span class="p">,</span> <span class="n">Listener</span>

<span class="k">if</span> <span class="n">TYPE_CHECKING</span><span class="p">:</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="kn">import</span> <span class="n">ndarray</span>


<span class="c1"># HASPI assumes the following audiogram frequencies:</span>
<span class="n">HASPI_AUDIOGRAM_FREQUENCIES</span><span class="p">:</span> <span class="n">Final</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">250</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">2000</span><span class="p">,</span> <span class="mi">4000</span><span class="p">,</span> <span class="mi">6000</span><span class="p">])</span>


<div class="viewcode-block" id="haspi_v2">
<a class="viewcode-back" href="../../../../clarity.evaluator.haspi.html#clarity.evaluator.haspi.haspi.haspi_v2">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">haspi_v2</span><span class="p">(</span>  <span class="c1"># pylint: disable=too-many-arguments too-many-locals</span>
    <span class="n">reference</span><span class="p">:</span> <span class="n">ndarray</span><span class="p">,</span>
    <span class="n">reference_sample_rate</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">processed</span><span class="p">:</span> <span class="n">ndarray</span><span class="p">,</span>
    <span class="n">processed_sample_rate</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">audiogram</span><span class="p">:</span> <span class="n">Audiogram</span><span class="p">,</span>
    <span class="n">level1</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">65.0</span><span class="p">,</span>
    <span class="n">f_lp</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">320.0</span><span class="p">,</span>
    <span class="n">itype</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">ndarray</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the HASPI intelligibility index using the</span>
<span class="sd">    auditory model followed by computing the envelope cepstral</span>
<span class="sd">    correlation and BM vibration high-level covariance. The reference</span>
<span class="sd">    signal presentation level for NH listeners is assumed to be 65 dB</span>
<span class="sd">    SPL. The same model is used for both normal and impaired hearing. This</span>
<span class="sd">    version of HASPI uses a modulation filterbank followed by an ensemble of</span>
<span class="sd">    neural networks to compute the estimated intelligibility.</span>

<span class="sd">    **NB** - The original HASPI model derivation included a bug which meant that</span>
<span class="sd">    although the &#39;shift&#39; parameter used in band centre frequency calculations was set to</span>
<span class="sd">    &#39;0.02&#39; it was never actually applied. To replicate this behaviour ear_model is</span>
<span class="sd">    called with &#39;shift&#39; set to None.  For discussion please refer to the discussion in</span>
<span class="sd">    `Issue #105 &lt;https://github.com/claritychallenge/clarity/issues/105&gt;`</span>
<span class="sd">    for further details.</span>

<span class="sd">    Args:</span>
<span class="sd">        reference (np.ndarray): Clear input reference speech signal with no noise or</span>
<span class="sd">            distortion. If a hearing loss is specified, no amplification should be</span>
<span class="sd">            provided.</span>
<span class="sd">        reference_sample_rate (int): Sampling rate in Hz for signal x</span>
<span class="sd">        processed (np.ndarray): Output signal with noise, distortion, HA gain, and/or</span>
<span class="sd">            processing.</span>
<span class="sd">        processed_sample_rate (int): Sampling rate in Hz for signal y.</span>
<span class="sd">        hearing_loss (np.ndarray): (1,6) vector of hearing loss at the 6 audiometric</span>
<span class="sd">            frequencies [250, 500, 1000, 2000, 4000, 6000] Hz.</span>
<span class="sd">        level1 (int): Optional input specifying level in dB SPL that corresponds to a</span>
<span class="sd">            signal RMS = 1. Default is 65 dB SPL if argument not provided.</span>
<span class="sd">        f_lp (int):</span>
<span class="sd">        itype (int): Intelligibility model</span>

<span class="sd">    Returns:</span>
<span class="sd">        tuple(Intel: float, raw: nd-array)</span>
<span class="sd">        Intel: Intelligibility estimated by passing the cepstral coefficients</span>
<span class="sd">              through a modulation filterbank followed by an ensemble of</span>
<span class="sd">              neural networks.</span>
<span class="sd">        raw: vector of 10 cep corr modulation filterbank outputs, averaged</span>
<span class="sd">              over basis functions 2-6.</span>

<span class="sd">    Updates:</span>
<span class="sd">        James M. Kates, 5 August 2013.</span>
<span class="sd">        Translated from MATLAB to Python by Zuzanna Podwinska, March 2022.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">audiogram</span><span class="o">.</span><span class="n">has_frequencies</span><span class="p">(</span><span class="n">HASPI_AUDIOGRAM_FREQUENCIES</span><span class="p">):</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
            <span class="s2">&quot;Audiogram does not have all HASPI frequency measurements&quot;</span>
            <span class="s2">&quot;Measurements will be interpolated&quot;</span>
        <span class="p">)</span>

    <span class="c1"># Adjust audiogram to match the standard frequencies</span>
    <span class="n">audiogram</span> <span class="o">=</span> <span class="n">audiogram</span><span class="o">.</span><span class="n">resample</span><span class="p">(</span><span class="n">HASPI_AUDIOGRAM_FREQUENCIES</span><span class="p">)</span>

    <span class="c1"># Auditory model for intelligibility</span>
    <span class="c1"># Reference is no processing, normal hearing</span>
    <span class="n">reference_env</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">processed_env</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">fsamp</span> <span class="o">=</span> <span class="n">ear_model</span><span class="p">(</span>
        <span class="n">reference</span><span class="p">,</span>
        <span class="n">reference_sample_rate</span><span class="p">,</span>
        <span class="n">processed</span><span class="p">,</span>
        <span class="n">processed_sample_rate</span><span class="p">,</span>
        <span class="n">audiogram</span><span class="o">.</span><span class="n">levels</span><span class="p">,</span>
        <span class="n">itype</span><span class="p">,</span>
        <span class="n">level1</span><span class="p">,</span>
        <span class="c1"># shift=0.02 # See comment in docstring</span>
        <span class="n">shift</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Envelope modulation features</span>

    <span class="c1"># LP filter and subsample the envelope</span>
    <span class="n">fsub</span> <span class="o">=</span> <span class="mf">8.0</span> <span class="o">*</span> <span class="n">f_lp</span>  <span class="c1"># subsample to span 2 octaves above the cutoff frequency</span>
    <span class="n">reference_lp</span><span class="p">,</span> <span class="n">processed_lp</span> <span class="o">=</span> <span class="n">env_filter</span><span class="p">(</span>
        <span class="n">reference_env</span><span class="p">,</span> <span class="n">processed_env</span><span class="p">,</span> <span class="n">f_lp</span><span class="p">,</span> <span class="n">fsub</span><span class="p">,</span> <span class="n">fsamp</span>
    <span class="p">)</span>

    <span class="c1"># Compute the cepstral coefficients as a function of subsampled time</span>
    <span class="n">nbasis</span> <span class="o">=</span> <span class="mi">6</span>  <span class="c1"># Use 6 basis functions</span>
    <span class="n">thr</span> <span class="o">=</span> <span class="mf">2.5</span>  <span class="c1"># Silence threshold in dB SL</span>
    <span class="n">dither</span> <span class="o">=</span> <span class="mf">0.1</span>  <span class="c1"># Dither in dB RMS to add to envelope signals</span>
    <span class="n">reference_cep</span><span class="p">,</span> <span class="n">processed_cep</span> <span class="o">=</span> <span class="n">cepstral_correlation_coef</span><span class="p">(</span>
        <span class="n">reference_lp</span><span class="p">,</span> <span class="n">processed_lp</span><span class="p">,</span> <span class="n">thr</span><span class="p">,</span> <span class="n">dither</span><span class="p">,</span> <span class="n">nbasis</span>
    <span class="p">)</span>

    <span class="c1"># Cepstral coefficients filtered at each modulation rate</span>
    <span class="c1"># Band center frequencies [2, 6, 10, 16, 25, 40, 64, 100, 160, 256] Hz</span>
    <span class="c1"># Band edges [0, 4, 8, 12.5, 20.5, 30.5, 52.4, 78.1, 128, 200, 328] Hz</span>
    <span class="n">reference_mod</span><span class="p">,</span> <span class="n">processed_mod</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">fir_modulation_filter</span><span class="p">(</span>
        <span class="n">reference_cep</span><span class="p">,</span> <span class="n">processed_cep</span><span class="p">,</span> <span class="n">fsub</span>
    <span class="p">)</span>

    <span class="c1"># Cross-correlation between the cepstral coefficients for the degraded and</span>
    <span class="c1"># ref signals at each modulation rate, averaged over basis functions 2-6</span>
    <span class="n">average_correlation_matrix</span> <span class="o">=</span> <span class="n">modulation_cross_correlation</span><span class="p">(</span>
        <span class="n">reference_mod</span><span class="p">,</span> <span class="n">processed_mod</span>
    <span class="p">)</span>

    <span class="c1"># Intelligibility prediction</span>
    <span class="c1"># Get the neural network parameters and the weights for an ensemble of 10 networks</span>
    <span class="p">(</span>
        <span class="n">neural_net_params</span><span class="p">,</span>
        <span class="n">weights_hidden</span><span class="p">,</span>
        <span class="n">weights_out</span><span class="p">,</span>
        <span class="n">normalization_factor</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">=</span> <span class="n">get_neural_net</span><span class="p">()</span>

    <span class="c1"># Average the neural network outputs for the modulation filterbank values</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">nn_feed_forward_ensemble</span><span class="p">(</span>
        <span class="n">average_correlation_matrix</span><span class="p">,</span> <span class="n">neural_net_params</span><span class="p">,</span> <span class="n">weights_hidden</span><span class="p">,</span> <span class="n">weights_out</span>
    <span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model</span> <span class="o">/</span> <span class="n">normalization_factor</span>

    <span class="c1"># Return the intelligibility estimate and raw modulation filter outputs</span>
    <span class="k">return</span> <span class="n">model</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">average_correlation_matrix</span></div>



<div class="viewcode-block" id="haspi_v2_be">
<a class="viewcode-back" href="../../../../clarity.evaluator.haspi.html#clarity.evaluator.haspi.haspi.haspi_v2_be">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">haspi_v2_be</span><span class="p">(</span>  <span class="c1"># pylint: disable=too-many-arguments</span>
    <span class="n">reference_left</span><span class="p">:</span> <span class="n">ndarray</span><span class="p">,</span>
    <span class="n">reference_right</span><span class="p">:</span> <span class="n">ndarray</span><span class="p">,</span>
    <span class="n">processed_left</span><span class="p">:</span> <span class="n">ndarray</span><span class="p">,</span>
    <span class="n">processed_right</span><span class="p">:</span> <span class="n">ndarray</span><span class="p">,</span>
    <span class="n">sample_rate</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">listener</span><span class="p">:</span> <span class="n">Listener</span><span class="p">,</span>
    <span class="n">level</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">100.0</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Better ear HASPI.</span>

<span class="sd">    Calculates HASPI for left and right ear and selects the better result.</span>

<span class="sd">    Args:</span>
<span class="sd">        ref_left (np.ndarray): left channel of reference signal</span>
<span class="sd">        ref_right (np.ndarray): right channel of reference signal</span>
<span class="sd">        proc_left (np.ndarray): left channel of processed signal</span>
<span class="sd">        proc_right (np.ndarray): right channel of processed signal</span>
<span class="sd">        sample_rate (int): sampling rate for both signal</span>
<span class="sd">        audiogram_left (): left ear audiogram</span>
<span class="sd">        audiogram_right (): right ear audiogram</span>
<span class="sd">        level: level in dB SPL corresponding to RMS=1</span>

<span class="sd">    Returns:</span>
<span class="sd">        float: beHASPI score</span>

<span class="sd">    Updates:</span>
<span class="sd">        Zuzanna Podwinska, March 2022</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">score_left</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">haspi_v2</span><span class="p">(</span>
        <span class="n">reference_left</span><span class="p">,</span>
        <span class="n">sample_rate</span><span class="p">,</span>
        <span class="n">processed_left</span><span class="p">,</span>
        <span class="n">sample_rate</span><span class="p">,</span>
        <span class="n">listener</span><span class="o">.</span><span class="n">audiogram_left</span><span class="p">,</span>
        <span class="n">level</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">score_right</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">haspi_v2</span><span class="p">(</span>
        <span class="n">reference_right</span><span class="p">,</span>
        <span class="n">sample_rate</span><span class="p">,</span>
        <span class="n">processed_right</span><span class="p">,</span>
        <span class="n">sample_rate</span><span class="p">,</span>
        <span class="n">listener</span><span class="o">.</span><span class="n">audiogram_right</span><span class="p">,</span>
        <span class="n">level</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="n">score_left</span><span class="p">,</span> <span class="n">score_right</span><span class="p">)</span></div>

</pre></div>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../../index.html">Project name not set</a></h1>








<h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../usage.html">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../recipes_doc.html">Recipes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../CONTRIBUTING.html">Contributing to pyClarity</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../CODE_OF_CONDUCT.html">Contributor Covenant Code of Conduct</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../clarity.html">clarity package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../recipes.html">recipes package</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../../index.html">Documentation overview</a><ul>
  <li><a href="../../../index.html">Module code</a><ul>
  </ul></li>
  </ul></li>
</ul>
</div>
<search id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 7.4.7</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 0.7.16</a>
      
    </div>

    

    
  </body>
</html>