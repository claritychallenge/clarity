{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gHAjmGrpv1wP"
   },
   "source": [
    "# Installing the Clarity tools and Interacting with Metadata\n",
    "\n",
    "This first tutorial walks through the process of installing the Clarity package and then using it to download and interact with some sample data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G0qNUxapSxUM"
   },
   "source": [
    "### Download and install the Clarity package\n",
    "\n",
    "The clarity enhancement challenge tools can be found at the Clarity <a href=\"https://github.com/claritychallenge/clarity\">GitHub</a> site.\n",
    "\n",
    "They can be downloaded into the notebook environment usung `git clone`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FoDXO-ILXrRB"
   },
   "outputs": [],
   "source": [
    "print(\"Cloning git repo...\")\n",
    "\n",
    "!git clone --quiet https://github.com/claritychallenge/clarity.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6A3rUdn_SxUS"
   },
   "source": [
    "This will have made a directory called <code>clarity</code> storing the package code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p6zresL-SxUT"
   },
   "source": [
    "The repository can now be installed as a python package using pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MaRf3d6GSxUU"
   },
   "outputs": [],
   "source": [
    "print(\"Changing directory...\")\n",
    "%cd clarity\n",
    "print(\"Installing Clarity tools\")\n",
    "%pip install -e .\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "print(\"Moving back to project root directory\")\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tBpkirNgSxUW"
   },
   "source": [
    "If you run `%pip list` then `clarity` should now appear in the alphabetic list of packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kSVPQIQ_SxUX"
   },
   "outputs": [],
   "source": [
    "%pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "je0YGzV9x02A"
   },
   "source": [
    "### Obtaining the sample data\n",
    "\n",
    "In order to demonstrate basic functionality, a smaller demo dataset is available through the <code>clarity.data.demo_data</code> module. Running the following functions downloads different components of the datasets:\n",
    "\n",
    "  - <code>get_metadata_demo()</code>\n",
    "  - <code>get_targets_demo()</code>\n",
    "  - <code>get_interferers_demo()</code>\n",
    "  - <code>get_rooms_demo()</code>\n",
    "  - <code>get_scenes_demo()</code>\n",
    "\n",
    "For this demonstration we will just download and install just the `metadata` dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ilDkGAzdXulr"
   },
   "outputs": [],
   "source": [
    "from clarity.data import demo_data\n",
    "\n",
    "demo_data.get_metadata_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vL1OH_IqSxUc"
   },
   "source": [
    "This will have created a directory called `clarity_data` containing the metadata files that have been downloaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gaRk7WW90_iz"
   },
   "source": [
    "---\n",
    "### The structure of the metadata files \n",
    "\n",
    "There are four metadata files \n",
    "\n",
    "- `rooms` - geometry of the rooms used for the simulations\n",
    "- `scenes` - information about the sound scene that is playing in the room\n",
    "- `listeners` - audiometric data for the hearing-impaired listeners who will listen to the scenes\n",
    "- `scenes_listeners` - a mapping assigning specific listeners to specific scenes (in the evaluation, each scene will be listened to by three separate listeners)\n",
    "\n",
    "Information about *individual* rooms, scenes, listeners etc is stored as a dictionary. The complete collections are then stored as either a list or dict depending on how the collection is mostly conveniently indexed. The datastructure of the four datatypes is summarized below.\n",
    "\n",
    "\n",
    "| Dataset | Structure | Index |\n",
    "| --- | --- | --- |\n",
    "| `rooms` | list of dicts | int |\n",
    "| `scenes` | list of dicts | int |\n",
    "| `listener` | dict of dicts | LISTENER_ID |\n",
    "| `scenes_listeners` | dict of lists | LISTENED_ID |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWF7zDVKSxUd"
   },
   "source": [
    "### Reading the metadata files\n",
    "\n",
    "The Clarity metadata is stored in JSON format. The python JSON library imports JSON files and parses them into python objects.\n",
    "\n",
    "This is demonstrated in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SrE0H-42isej"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"clarity_data/demo/metadata/scenes.demo.json\") as f:\n",
    "    scenes = json.load(f)\n",
    "\n",
    "with open(\"clarity_data/demo/metadata/rooms.demo.json\") as f:\n",
    "    rooms = json.load(f)\n",
    "\n",
    "with open(\"clarity_data/demo/metadata/listeners.json\") as f:\n",
    "    listeners = json.load(f)\n",
    "\n",
    "with open(\"clarity_data/demo/metadata/scenes_listeners.dev.json\") as f:\n",
    "    scenes_listeners = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZcSKwqIjcEn3"
   },
   "source": [
    "---\n",
    "### Working with the metadata\n",
    "\n",
    "Once the data is loaded, we can access the dictionary for an individual item using the items index, and then we can access the parameters of that item using the dictionary's keys. \n",
    "\n",
    "For example, we will retrieve the information about the first scene and then use the `keys` method to see what scene parameters are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gSeAvNm3WccT"
   },
   "outputs": [],
   "source": [
    "scene_0 = scenes[0]\n",
    "\n",
    "print(scene_0.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kS36TcFfSxUg"
   },
   "source": [
    "We can see that for the scene we have the following list of keys\n",
    "\n",
    "- dataset\n",
    "- room\n",
    "- scene\n",
    "- target\n",
    "- duration\n",
    "- interferers\n",
    "- SNR\n",
    "- listener\n",
    "\n",
    "To find out the SNR of this scene we can simply use the `SNR` key, i.e., `scene_0['SNR']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xQZa6rimSxUh"
   },
   "outputs": [],
   "source": [
    "print(scene_0[\"SNR\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_39YsucZdf5d"
   },
   "source": [
    "### Processing a collection of scenes\n",
    "\n",
    "We can then run processes over the complete list of scenes using standard Python list processing idioms.\n",
    "\n",
    "So for example, in the code below we extract the SNR from each scene and plot a histogram of this set of SNRs. We can then use the `interferers` field to separate scenes according to whether they have either two or three interferers and compare the range of SNRs for each type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XHOb_v1NW5EN"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "# Get list of SNRs of scenes\n",
    "snr_values = np.array([s[\"SNR\"] for s in scenes], dtype=\"float32\")\n",
    "\n",
    "# Plot histogram\n",
    "ax[0].hist(snr_values)\n",
    "ax[0].set_title(\"Histogram of SNR values\")\n",
    "ax[0].set_xlabel(\"SNR (dB)\")\n",
    "\n",
    "# Get list of number of interferers in scenes\n",
    "n_interferers = np.array([len(s[\"interferers\"]) for s in scenes], dtype=\"int32\")\n",
    "\n",
    "# Prepare data for boxplot\n",
    "snr_comparison_data = [\n",
    "    [s for s, n in zip(snr_values, n_interferers) if n == 2],\n",
    "    [s for s, n in zip(snr_values, n_interferers) if n == 3],\n",
    "]\n",
    "\n",
    "# Plot boxplot\n",
    "ax[1].boxplot(np.array(snr_comparison_data, dtype=\"object\"))\n",
    "ax[1].set_xlabel(\"Number of interferers\")\n",
    "ax[1].set_ylabel(\"SNR (dB)\")\n",
    "\n",
    "plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.4, hspace=0.4)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dXgokocLlO-y"
   },
   "source": [
    "---\n",
    "## Associations between metadata types\n",
    "\n",
    "There are various associations between the metadata types which sometime require cross referencing from one collection to another. \n",
    "\n",
    "For example, room dimensions are stored in the room dict rather than directly in the scene dict. So to get the room dimensions for a given scene, you need to first look at the room ID field in the scene to find the correct room.\n",
    "\n",
    "One approach to doing this is shown below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XMV3r2ApSxUj"
   },
   "outputs": [],
   "source": [
    "room_id = scene_0[\"room\"]\n",
    "\n",
    "# Iterate through rooms to find the one named `room_id`\n",
    "\n",
    "room = next((item for item in rooms if item[\"name\"] == room_id), None)\n",
    "\n",
    "print(room[\"dimensions\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Qw_W8l5SxUj"
   },
   "source": [
    "This approach uses a linear search and is therefore not very efficient. If you are going to be doing this often you might want to convert the list of rooms into a dictionary indexed by room ID, e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SyX83YKMSxUk"
   },
   "outputs": [],
   "source": [
    "room_dict = {room[\"name\"]: room for room in rooms}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q4icku47SxUk"
   },
   "source": [
    "You can now look up the dimensions of a scene's room more efficiently,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Oq1TYP7SxUl"
   },
   "outputs": [],
   "source": [
    "room_id = scene_0[\"room\"]\n",
    "room_dict[room_id]\n",
    "print(room[\"dimensions\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "waOj0yIsSxUl"
   },
   "source": [
    "### Example: Locating information about the scene's listener\n",
    "\n",
    "We will now use these ideas to plot the audiograms of one of the listeners associated with a specific scene. The code also prints out some information about the target and listener locations that are stored in the scene's associated room dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ms1DrhVMl0DL"
   },
   "outputs": [],
   "source": [
    "scene_no = 32  # this is just an arbitrary index. try any from 0 - 49\n",
    "\n",
    "scene = scenes[scene_no]\n",
    "\n",
    "room = room_dict[scene[\"room\"]]\n",
    "current_listeners = scenes_listeners[scene[\"scene\"]]\n",
    "\n",
    "\n",
    "print(\n",
    "    f'\\nScene number {scene_no}  (ID {scene[\"scene\"]}) has room dimensions of {room[\"dimensions\"]}'\n",
    ")\n",
    "\n",
    "print(\n",
    "    f'\\nSimulated listeners for scene {scene_no} have spatial attributes: \\n{room[\"listener\"]}'\n",
    ")\n",
    "\n",
    "print(f'\\nAudiograms for listeners in Scene ID {scene[\"scene\"]}')\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, len(current_listeners))\n",
    "\n",
    "ax[0].set_ylabel(\"Hearing level (dB)\")\n",
    "for i, l in enumerate(current_listeners):\n",
    "    listener_data = listeners[l]\n",
    "    (left_ag,) = ax[i].plot(\n",
    "        listener_data[\"audiogram_cfs\"],\n",
    "        -np.array(listener_data[\"audiogram_levels_l\"]),\n",
    "        label=\"left audiogram\",\n",
    "    )\n",
    "    (right_ag,) = ax[i].plot(\n",
    "        listener_data[\"audiogram_cfs\"],\n",
    "        -np.array(listener_data[\"audiogram_levels_r\"]),\n",
    "        label=\"right audiogram\",\n",
    "    )\n",
    "    ax[i].set_title(f\"Listener {l}\")\n",
    "    ax[i].set_xlabel(\"Hz\")\n",
    "    ax[i].set_ylim([-100, 10])\n",
    "\n",
    "plt.legend(handles=[left_ag, right_ag])\n",
    "plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.4, hspace=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "STUVedX7SxUm"
   },
   "source": [
    "We hope this tutorial has been useful. We will be releasing future tutorials demonstrating how to build other useful visualisations of the metadata. If you have any feedback or questions please feel free to contact us. Contact details are available on the Clarity project websites.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Installing_clarity_tools_and_using_metadata.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "415f7560f72a1f526cbd5fabf4edcf108298e909bd053a2408002bb17c3fd4fa"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 64-bit ('clarity')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
